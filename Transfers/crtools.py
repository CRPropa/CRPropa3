import pandas as pd
import numpy as np
from glob import glob
import os
from scipy.interpolate import interp1d
from scipy.integrate import quad
try:
    import crpropa as crp
    crp_flag = True
except:
    crp_flag = False
    import siunits as siu
    print ("Import error: crpropa\nLimited functionality")

##########################################################
# Basic
##########################################################
class AttrDisplay(object):
    """
    Provides an inheritable display overload method that
    shows instances with their class names and a name=value
    pair for each attribute stored on the instance itself (but
    not attrs inherited from its classes). Can be mixed into any
    class and will work on any instance.
    """
    
    def getAttr(self, key):
        try:
            return getattr(self, key).head()
        except:
            return getattr(self, key)
    
    def gatherAttrs(self):
        attrs = []
        for key in sorted(self.__dict__):
            attrs.append("{}={}".format(key, self.getAttr(key)))
        return '\n'.join(attrs)
    
    def __str__(self):
        return "{}:\n {}".format(self.__class__.__name__, self.gatherAttrs())
    
    #def __repr__(self):
    #    return "{}".format(self.__class__.__name__)

##########################################################
# Helper Functions

def is_sequence(arg):
    return (not hasattr(arg, "strip") and
            hasattr(arg, "__getitem__") or
            hasattr(arg, "__iter__"))

def is_number(arg):
    return isinstance(arg, (float, int))

def is_binEdges(arg):
    if not is_sequence(arg): 
        return False
    else:
        if not sum([is_number(a) for a in arg]) == len(arg):
            return False
        elif not sorted(list(arg))==list(arg): #because sorted(np.array)==np.array is evaluated elementwise
            return False
        else: 
            return True
        
def splitEnergyRange(arg, cut):
    s = pd.Series(arg)
    less = s[s<cut]
    more = s[s>=cut]
    
    return less, more

def combineEnergyRange(s1,s2):
    
    return s1.append(s2).sort_index()


    
##########################################################
# Data structures
##########################################################

class CRPropa_Data(AttrDisplay):
    """Base class for data generated by CRPropa"""
    
    def __init__(self, path):
        if os.path.isfile(path):
            self.dataPath = path   
        else:
            print ('File '+str(path)+' does not exist.')
    
    def searchDataSize(self):
        try:
            size = os.path.getsize(self.dataPath)
        except Exception as e:
            print (e)
            print ('This is probably because the data path is wrong.')
            return
            
        logSize = np.log2(size)
        if logSize < 10:
            self.dataSize = str(size)+' byte'
        elif logSize < 20:
            self.dataSize = str(size/1024)+' kB'
        elif logSize < 30:
            self.dataSize = str(size/2**20)+' MB'
        else:
            self.dataSize = str(size/2**30)+' GB'
    
    def searchData(self):
        
        try:    
            with open(self.dataPath, 'r') as f:
                header = f.readline()
        except AttributeError as e:
            print (e)
            print ('This is probably because the data path is wrong.')
            return None
        
        if header[0] != '#':
            print ("Not a CRPropa data file:\nFirst line should start with '#' but was "+header[0])
            return None
        
        columns = (header[2:-1]).split('\t')
        if (len(columns))==0:
            print ("No data columns extracted from header: "+header)
            return None
        
        self.dataColumns = columns
        self.searchDataSize()
        return 'CRPropaData is found at '+self.dataPath
        
    def loadData(self, **kwargs): 
        try:
            df = pd.read_csv(self.dataPath, delimiter='\t', names=self.dataColumns, comment='#', **kwargs)
            self.data = df
            return self.dataSize+' data succesfully loaded.'
        except AttributeError as e:
            test = self.searchData()
            if test != None: 
                self.loadData(**kwargs)
                return self.dataSize+' data succesfully loaded.'
        return 'Unknown Problem while loading the data.'
            
    def get(self, *args):
        if len(args)==1:
            return self.data[args[0]]
        return [self.data[a] for a in args]
    
class Simulation(CRPropa_Data):
    
    def __init__(self, path, **kwargs):
        
        CRPropa_Data.__init__(self, path)
        
        for k, v in kwargs.items():
            self.__setattr__(k, v)
            
    def addAttribute(self, Dict):
        try:
            for k, v in Dict.items():
                if k not in self.__dict__.keys():
                    self.__setattr__(k, v)
                else:
                    print ("The attribute <{}> is already defined.\nUse updateAttribute() instead".format(k) )
        except AttributeError:
            print ("A dictionary is needed but <{}> was used".format(type(Dict)) )
                
    def updateAttribute(self, Dict):
        try:
            self.__dict__.update(Dict)
        except AttributeError:
            print ("A dictionary is needed but <{}> was used".format(type(Dict)) )
    
    def removeAttribute(self, Keys):
        for k in Keys:
            if k not in self.__dict__.keys():
                print ("Key <{}> is not an Attribute.")
            else:
                del self.__dict__[k]

class TerminationShock_Simulation(Simulation):
    
    def loadData(self, **kwargs):
        """Load data and add a column 'T' for 
        the propagation time in Myr"""
        
        Simulation.loadData(self, **kwargs)
        if crp_flag:
            self.data['T'] = self.data.D*crp.kpc/crp.c_light/3600/24/365.25/1e6
        else: 
            self.data['T'] = self.data.D*siu.kpc/siu.c_light/3600/24/365.25/1e6
        
        
##########################################################
# Tools
##########################################################

class Tool(AttrDisplay):
    
    def __init__(self, DataSet):
        self.DataSet = DataSet
        self.ActionList = {}
    
    def performActions(self):
        for a in self.ActionList.keys():
            Args, Kwargs = self.ActionList[a]['args'], self.ActionList[a]['kwargs']
            self.ActionList[a]['func'](*Args, **Kwargs)
            
    def addAction(self, action, args=[], kwargs={}):
        name = action.__name__
        if name in self.ActionList.keys():
            print ("Warning: Action {} is already defined".format(name))
        else:
            self.ActionList[action.__name__] = {'func': action, 'args': args, 'kwargs': kwargs}
    
    def removeAction(self, action):
        name = action.__name__
        if name in self.ActionList.keys():
            del self.ActionList[action.__name__]
        else:
            print ("Warning: Action {} is not in ActionList".format(name))
            
    def removeAll(self):
        self.ActionList = {}


##########################################################
# Weighting

class Weighting(Tool):
    
    def weight(self, w):
        try:
            self.DataSet.data['Weight'] *= w
        except:
            self.DataSet.data['Weight'] = w

    def removeAllWeights(self):
        del self.DataSet.data['Weight']
        
        # remove weight entries from ActionList
        #Tool.
    
    def constantWeight(self, const, add=True):
        self.constWeight = const
        w = np.ones(len(self.DataSet.data))*const
        
        if add:
            self.weight(w)
        else:
            return w
        
    def reweightSpectrum(self, gamma_old, gamma_new, add=True):
        cols = self.DataSet.dataColumns
        if 'E' not in cols or 'E0' not in cols:
            print ("E and/or E0 not found")
            return
        E, E0 = self.data.E, self.data.E0
        w = E0**(gamma_new-gamma_old) * len(E0) / (E0**(gamma_new-gamma_old)).sum()
        self.spectralWeight = 'gamma_old={}, gamma_new={}'.format(gamma_old, gamma_new)
        if add:
            self.weight(w)
        else:
            return w
        
class TerminationShock_Weighting(Weighting):
    
    def totalWeight(self):
        try:  
            erg = 1e-7*crp.joule
            SourceLuminosity = 1e40*erg/crp.second #total CR luminosity of the termination shock
            lumFrac = 1/7. # fraction of the luminosity between (1e15 and 1e16) eV
            simEnergy = 4098.43526694 * crp.joule / 1e7 * self.DataSet.nSim # Total simulated energy in Joule nSim = # of simulated
        except:
            erg = 1e-7*siu.joule
        
            SourceLuminosity = 1e40*erg/siu.second #total CR luminosity of the termination shock
            lumFrac = 1/7. # fraction of the luminosity between (1e15 and 1e16) eV
            simEnergy = 4098.43526694 * siu.joule / 1e7 * self.DataSet.nSim # Total simulated energy in Joule nSim = # of simulated particles

        norm = SourceLuminosity * lumFrac / simEnergy  # normalization factor
        
        Weighting.constantWeight(self, norm)

##########################################################
# Filtering

class Filtering(Tool):

    def __init__(self, DataSet):
        Tool.__init__(self, DataSet)
        self.FilteredData = self.DataSet.data.copy()
        
        
    def getFiltered(self):
        """Returns a new instance of a CRPropa_Data object:
        Reuses the attributes of self.DataSet and adds the 
        ActionList of self. The data is only the filtered data.
        """
        
        Data = CRPropa_Data(self.DataSet.dataPath)
        for k, v in self.DataSet.__dict__.items():
            if k not in ['dataPath', 'data']:
                Data.__setattr__(k, v)
        Data.__setattr__('data', self.FilteredData)
        for k, v in self.ActionList.items():
            Data.__setattr__(k, v)
        Data.__setattr__('0_Filtered', True)
        return Data

    
    def resetFilter(self):
        Tool.removeAll(self)
        self.FilteredData = self.DataSet.data.copy()
            
    
    def minimumCut(self, Column, Cut):
        self.FilteredData = self.FilteredData[self.FilteredData[Column] >= Cut]
        
    def maximumCut(self, Column, Cut):
        self.FilteredData = self.FilteredData[self.FilteredData[Column] <= Cut]
        
    def minimumEnergyCut(self, E_min):
        self.minimumCut('E', E_min)
    
    def maximumEnergyCut(self, E_max):
        self.maximumCut('E', E_max)
        
    def rangeCut(self, Column, Min, Max):
        if Min > Max:
            raise ValueError("Min={} is larger than Max={}".format(Min, Max))
            
        self.FilteredData = self.FilteredData[(self.FilteredData[Column] <= Max) 
                                              & (self.FilteredData[Column] >= Min)]
        
    def equals(self, Column, Val):
        self.FilteredData = self.FilteredData[self.FilteredData[Column] == Val]

class TerminationShock_Filter(Filtering):
    
    def observedCR(self, t_obs, delta_t, t_0=0):
        """Filters a dataframe to provide observed data only
        t_min = max(t_0, tobs-delta_t)
        t_max = t_obs-t_0
        All data with t_min < T < t_max"""

        t_min = max(t_0, t_obs-delta_t)
        t_max = t_obs-t_0
        Filtering.rangeCut(self, 'T', t_min, t_max)
        
        
##########################################################
# Observing
##########################################################

class Observing(AttrDisplay):
    
    def dumpData(self):
        pass
    
    def loadData(self):
        pass

class Fluxes(Observing):
    """Base Class for Flux modeling"""
    
    def __init__(self, E, binEdges, Weight=None):
        self.E = E
        self.binEdges = self.setBinEdges(binEdges)
        self.Weight = Weight
        
    def setBinEdges(self, binEdges=None, scale='log', bins=20, Min=None, Max=None):
        if Min == None: MIN=self.E.min()
        if Max == None: MAX=self.E.max()
        #default values for bins 20 bins on logscale 
        if is_binEdges(binEdges):
            return binEdges
        elif binEdges == None:
            if (not isinstance(bins, int) or bins < 1):
                raise AttributeError("bins has to be positive integer")
            if scale == 'lin':
                return np.linspace(MIN, MAX, bins+1)
            if scale == 'log':
                return np.logspace(np.log10(MIN), np.log10(MAX), bins+1)
            else:
                raise AttributeError("scale has to be 'lin' or 'log'")
        else:
            raise AttributeError("binEdges={} cannot be converted to binEdges".format(binEdges))
        
        
        
    
    def meanEnergy(self, count=False):
        """Calculates the mean of binned Series object
        If count=true the count per bin is also returned"""
        
        _E = (self.E).groupby(pd.cut(self.E, self.binEdges))
        try:
            def wm(x):
                try:
                    return np.average(x, weights=self.Weight.loc[x.index])
                except ZeroDivisionError:
                    return np.nan
            wc = lambda x: np.sum(self.Weight.loc[x.index])
            if count:
                E_count = _E.apply(wc)
            E_mean = _E.apply(wm)
        except AttributeError:
            if count:
                E_count = _E.count()
            E_mean = _E.mean()
        
        E_masked = np.ma.masked_invalid(E_mean)
        
        if count:
            C_masked = np.ma.masked_array(E_count, mask=E_masked.mask)
            return C_masked, E_masked
        return E_masked
            
        
    def Spectrum(self, r, A=4*np.pi):
        """Calculates the Spectrum from a given array-like energy object
        Returns units of 1/(<unit of E><unit of Weight>)"""
        binEdges = self.binEdges
        #E = self.E
        N, Emean = self.meanEnergy(count=True)
        Flux = N /(4*np.pi*r**2.) / A / (binEdges[1:]-binEdges[:-1])

        return Emean, Flux, Flux/np.sqrt(N)
    
    def continuesSpectrum(self, r, A=4*np.pi, **kwargs):
        """"Callable interpolation of the Spectrum function"""
        
        E, F, delF = self.Spectrum(r, A)
        _kwargs = {'kind': 'linear', 'bounds_error': False, 'fill_value': 0}
        _kwargs.update(kwargs)
        wrg_msg = "-"*70 + "\n WARNING: A high order of interpolation might lead to negative fluxes!\n" + "-"*70
        if _kwargs['kind'] not in ['linear', 'nearest', 'zero', 'slinear']:
            print (wrg_msg)
        #Look here for more sophisticated ideas
        #Fitting-a-power-law-to-data-with-errors
        #https://scipy-cookbook.readthedocs.io/items/FittingData.html
        #compress masked arrays to get rid of NaN which led to problems
        f = interp1d(E.compressed(), F.compressed(), **_kwargs)
        
        return f
    
    def Luminosity(self):
        """Calculates the Luminosity from a given array-like energy object
        Returns units of (<unit of E><unit of Weight>)"""
        try:
            L = (self.E*self.Weight).sum()
            N = self.E.count()
        except:
            L = self.E.sum()
            N = self.E.count()
        return L, L/np.sqrt(N)

class neutrinoFluxes(Fluxes):
    
    def __init__(self, E, binEdges, r=None, A=4*np.pi, Weight=None, protonFlux=None):
        
        Fluxes.__init__(self, E, binEdges, Weight=Weight)
        self.mp_c2 = 0.9382720813 #proton mass in GeV/c^2
        self.mpi_c2 = 0.13957018 #pion (plus/minus) mass in GeV/c^2
        if callable(protonFlux):
            self.protonFlux=protonFlux
            if r!=None:
                print ("r={} is ignored because a callable for the proton flux is defined".format(r))
            if A!=4*np.pi:
                print ("A={} is ignored because a callable for the proton flux is defined".format(A))
        elif r != None:
            self.protonFlux = Fluxes.continuesSpectrum(self, r, A)
        
    
    #Helper functions
    def F_nu_mu_1(self, x, E_p):
        """Equation (66) in Kelner et al. (2006)"""

        L = np.log(E_p/1e3)

        B_prime = 1.75 + 0.204*L + 0.010*L*L
        beta_prime = 1./(1.67 + 0.111*L + 0.0038*L*L)
        k_prime = 1.07 - 0.086*L + 0.002*L*L

        y = x/0.427 #1-(m_mu/m_pi)^2

        # mask values for x>0.427 due to numerical problems
        # F should drop off rapidly but has a pole increses afterwards
        y =  np.ma.masked_greater_equal(y, 1)

        logY = np.log(y)
        y_beta = y**beta_prime
        logY_beta = logY**beta_prime

        A = B_prime * logY / y
        B = ( 1-y_beta ) / ( 1. + k_prime*y_beta*(1-y_beta) )
        C = ( 4*beta_prime*y_beta) / ( 1-y_beta )
        D = (4*k_prime*beta_prime*y_beta * (1-2*y_beta) ) / ( 1 + k_prime*y_beta * (1-y_beta) )

        F = A*B**4. * ( 1./logY - C - D )
        try:
            return F.filled(0.)
        except:
            return F

    def F_e(self, x, E_p):
        """Equation (62) in Kelner et al. (2006)"""

        L = np.log(E_p/1e3)

        B_e = 1 / (69.5 + 2.65*L + 0.3*L*L)
        beta_e = 1./(0.201 + 0.062*L + 0.00042*L*L)**(1./4.)
        k_e = ( 0.279 + 0.141*L + 0.0172*L*L ) / ( 0.3 + (2.3+L)**2. )

        F = B_e * ( 1+k_e*(np.log(x))**2. )**3. / ( x * (1+0.3/x**beta_e) ) * (-np.log(x))**5.

        return F
    
    def crossSection(self, E_p):
        """"Equation (73) in Kelner et al (2006)"""
        
        barn = 1e-24 # centimeter^2
        mb = 1e-3*barn
        
        L = np.log(E_p/1e3)
        
        sigma = 34.3 + 1.88*L + 0.25*L*L
        E_th = self.mp_c2 + self.mpi_c2 + self.mpi_c2**2./self.mp_c2
        
        return sigma * ( 1 - (E_th/E_p)**4. )**2. * mb
    
    def Xi(self, E_p):
        E_th = self.mp_c2 + self.mpi_c2 + self.mpi_c2**2./self.mp_c2
        return 2*((E_p-E_th)/1e3)**(1./4.) # additional 1/1e3: converting GeV to TeV because equation was originally given in TeV

    def MeanPionEnergy(self, E_p):

        return 1./6.*(E_p-self.mp_c2)**(3./4.)
    
    def MeanPionEnergy_prime(self, E_p):
        return -3./24.*((E_p-self.mp_c2)/1e3)**(-1./4.) # additional 1/1e3: converting GeV to TeV because equation was originally given in TeV

    def ProtonEnergy_for_PionEnergy(self, E_pi):

        return (6*E_pi/1e3)**(4./3.)*1e3 + self.mp_c2 # additional 1/1e3: converting GeV to TeV because equation was originally given in TeV

    
    def PionFlux(self, E_pi, N=1e24):
        
        E_p = self.ProtonEnergy_for_PionEnergy(E_pi)
        
        E_th = self.mp_c2 + self.mpi_c2 + self.mpi_c2**2./self.mp_c2
        E_masked =  np.ma.masked_less(E_p, E_th)
        
        scale = 1.6 #accounts for all additional target material
        xi = self.Xi(E_masked.compressed())
        j_p = self.protonFlux(E_masked.compressed())
        factor_from_deltaFunction = 1./abs(self.MeanPionEnergy_prime(E_masked.compressed()))
        sigma = self.crossSection(E_masked.compressed())
        
        q_pi = scale *N * sigma * xi * factor_from_deltaFunction * j_p
        
        return q_pi
    
    ################################################
    
    #high energies
    def Phi_nu_mu1(self, E_nu, N=1e24):
        #check this
        """Probably Equation (71) in Kelner et al (2006)""" 
        try:
            phi = [0.]*len(E_nu)

            Int = lambda x: self.crossSection(x) * self.protonFlux(x) * self.F_nu_mu_1(E_nu/x, x) / x

            for i, E_nu in enumerate(E_nu):
                logE_min = np.log10(E_nu)
                logE_max = 10

                Intervals = int(np.ceil(logE_max-logE_min))

                IntegrationBoundary = np.logspace(logE_min, logE_max, Intervals+1)
                #print IntegrationBoundary

                for j in range(Intervals):
                    phi[i] += 1.6*N*quad(Int, IntegrationBoundary[j], IntegrationBoundary[j+1])[0]

            return np.array(phi)

        except TypeError as e:
            phi = 0.

            Int = lambda x: self.crossSection(x) * self.protonFlux(x) * self.F_nu_mu_1(E_nu/x, x) / x

            logE_min = np.log10(E_nu)
            logE_max = 10

            Intervals = int(np.ceil(logE_max-logE_min))
            IntegrationBoundary = np.logspace(logE_min, logE_max, Intervals+1)
            #print IntegrationBoundary
            for i in range(Intervals):
                phi += 1.6*N*quad(Int, IntegrationBoundary[i], IntegrationBoundary[i+1])[0]
                print (phi)

            return phi
        
    def Phi_nu_e(self, E_nu, N=1e24):
        try:
            phi = [0.]*len(E_nu)

            Int = lambda x: self.crossSection(x) * self.protonFlux(x) * self.F_e(E_nu/x, x) / x

            for i, E_nu in enumerate(E_nu):
                logE_min = np.log10(E_nu)
                logE_max = 10

                Intervals = int(np.ceil(logE_max-logE_min))
                
                IntegrationBoundary = np.logspace(logE_min, logE_max, Intervals+1)
                #print IntegrationBoundary
                for j in range(Intervals):
                    phi[i] += 1.6*N*quad(Int, IntegrationBoundary[j], IntegrationBoundary[j+1])[0]

            return np.array(phi)

        except TypeError as e:
            phi = 0.

            Int = lambda x: self.crossSection(x) * self.protonFlux(x) * self.F_e(E_nu/x, x) / x

            logE_min = np.log10(E_nu)
            logE_max = 10

            Intervals = int(np.ceil(logE_max-logE_min))

            IntegrationBoundary = np.logspace(logE_min, logE_max, Intervals+1)
            #print IntegrationBoundary

            for i in range(Intervals):
                phi += 1.6*N*quad(Int, IntegrationBoundary[i], IntegrationBoundary[i+1])[0]
                print (phi)

            return phi
    
    ################################################
    
    #low energy
    def deltaKelnerNeutrinoFlux(self, E_nu, N=1e24, n_tilde='norm'):
        
        if n_tilde=='norm':
            normFlux = self.Phi_nu_mu1(1e2)+2*self.Phi_nu_e(1e2)
            try:
                n_tilde = normFlux/float(self.deltaKelnerNeutrinoFlux(1e2, N=N, n_tilde=1.))
            except ZeroDivisionError as e:
                print ("Cannot normalize at E=100 GeV because the delta functional approach yields no flux")
                print (e)
                n_tilde = 1.
            
                
        K_pi = 0.17
        E_pi = E_nu*4. #every lepton gets 1/4th of the pion energy
        E_p = E_pi/K_pi + self.mp_c2
        
        E_th = self.mp_c2 + self.mpi_c2 + self.mpi_c2**2./self.mp_c2
        E_masked =  np.ma.masked_less(E_p, E_th)
        sigma = self.crossSection(E_masked.compressed())
        j_p = self.protonFlux(E_masked.compressed())
        factor_from_deltaFunction = 1./K_pi
        q = 1.6*N * j_p*sigma*factor_from_deltaFunction*n_tilde
        
        return q
    
    def deltaSchlickeiserNeutrinoFlux(self, E_nu, N=1e24, n_tilde='norm'):
        
        """Use with caution.
        Not yet completely checked!"""
        
        if n_tilde=='norm':
            normFlux = self.Phi_nu_mu1(1e2)+2*self.Phi_nu_e(1e2)
            try:
                n_tilde = normFlux/float(self.deltaSchlickeiserNeutrinoFlux(1e2, N=N, n_tilde=1.))
            except ZeroDivisionError as e:
                print ("Cannot normalize at E=100 GeV because the delta functional approach yields no flux")
                print (e)
                n_tilde = 1.
                
        E_pi = 4*E_nu
        print (deltaSchlickeiserNeutrinoFlux.__doc__)
        return 4*self.PionFlux(E_pi, N=N)*n_tilde
    
    def totalNeutrinoFlux(self, E_nu, N=1e24, n_tilde='norm'):
        
        less, more = splitEnergyRange(E_nu, 100)
        
        if len(less):
            f_low = pd.Series(self.deltaKelnerNeutrinoFlux(less, N=N, n_tilde='norm'), index=less.index)
        
        if len(more):
            f_high = pd.Series(2*self.Phi_nu_e(more, N=N)+self.Phi_nu_mu1(more, N=N), index=more.index)
        
        try:
            F = combineEnergyRange(f_low, f_high)
        except UnboundLocalError:
            try:
                F = f_low
            except UnboundLocalError:
                F = f_high
        return F
        
